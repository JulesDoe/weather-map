{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "f85c0ae1067a86ad6a96b144378883e79fd1516474b579ba33ee3a7084540002"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "source": [
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Parsing the Whole Folder"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "source": [
    "# Reading the whole folder\n",
    "\n",
    "entities = []\n",
    "\n",
    "# The index of these four arrays corresponds to one organization\n",
    "\n",
    "orgs = []\n",
    "texts = []\n",
    "years = []\n",
    "occurences = []\n",
    "\n",
    "# The template counts the occurencies for each organization\n",
    "\n",
    "years_template = {\n",
    "    2011: 0,\n",
    "    2012: 0,\n",
    "    2013: 0,\n",
    "    2014: 0,\n",
    "    2015: 0,\n",
    "    2016: 0,\n",
    "    2017: 0,\n",
    "    2018: 0,\n",
    "    2019: 0,\n",
    "    2020: 0\n",
    "}\n",
    "\n",
    "dir = 'data/biomass/'\n",
    "files = os.listdir(dir)\n",
    "\n",
    "for index, filename in enumerate(files):\n",
    "\n",
    "    # Read one file\n",
    "    \n",
    "    f = open(dir + filename)\n",
    "    r = f.read()\n",
    "    data = json.loads(r)\n",
    "    \n",
    "    \n",
    "    # Set basic metadata\n",
    "\n",
    "    try:\n",
    "        year = int(data[0]['publish_date'].split(' ')[0].split('-')[0]) # Set year\n",
    "        records = data[0]['story_tags'] # Set tags\n",
    "        # if len(tags) > 1000: continue # Limit the maxiumum number of tags\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        print(index, '/', len(files), end=' ')\n",
    "    \n",
    "    except:\n",
    "        continue\n",
    "\n",
    "\n",
    "    # Collect entities\n",
    "    \n",
    "    tags = []\n",
    "\n",
    "    for record in records:\n",
    "        # If the record is an organization\n",
    "        if (record['tag_set'] == 'cliff_organizations'):\n",
    "            tag = record['tag']\n",
    "            tag = tag.replace('.', '')\n",
    "            # If the tag starts with lowercase\n",
    "            if tag[0].islower():\n",
    "                continue\n",
    "            tags.append(tag)\n",
    "    \n",
    "    \n",
    "    # Collect entities by name\n",
    "\n",
    "    for t in tags:\n",
    "\n",
    "        related = tags.copy()\n",
    "        related.remove(t)    \n",
    "    \n",
    "        if t not in orgs:\n",
    "\n",
    "            orgs.append(t)\n",
    "            i = orgs.index(t)\n",
    "\n",
    "            texts.append(related)\n",
    "\n",
    "            occurences.append(1)\n",
    "            \n",
    "            years.append(years_template.copy())\n",
    "            years[i][year] += 1\n",
    "                \n",
    "        else:\n",
    "\n",
    "            i = orgs.index(t)\n",
    "\n",
    "            # print(texts[i])\n",
    "            texts[i] += related\n",
    "            # print(texts[i])\n",
    "\n",
    "            occurences[i] += 1\n",
    "            \n",
    "            years[i][year] += 1\n",
    "\n",
    "    # if index > 10:\n",
    "    #     raise SystemExit(\"Stop right there!\")\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "26449 / 26450 "
     ]
    }
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "source": [
    "# tests\n",
    "\n",
    "n = 100\n",
    "\n",
    "orgs[n]\n",
    "# texts[n]\n",
    "# len(texts[n])\n",
    "# years[n]\n",
    "occurences[n]\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "metadata": {},
     "execution_count": 98
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Cleaning"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "source": [
    "\n",
    "# Remove less citates organizations\n",
    "\n",
    "for index, occurrence in reversed(list(enumerate(occurences))):\n",
    "\n",
    "    min = 50\n",
    "\n",
    "    if occurrence < min:\n",
    "        orgs.pop(index)\n",
    "        texts.pop(index)\n",
    "        years.pop(index)\n",
    "        occurences.pop(index)\n",
    "    # else:\n",
    "        # print()\n",
    "        # print(index, occurrence, orgs[index])\n",
    "        # print()\n",
    "\n",
    "# order years by key in an array of tuples\n",
    "\n",
    "for index, y in enumerate(years):\n",
    "    sortedDict = dict( sorted(y.items(), key=lambda x: x[0]) )\n",
    "    _temp = {}\n",
    "    for k,v in sortedDict.items():\n",
    "        _temp[k] = v\n",
    "    years[index] = _temp\n",
    "\n",
    "print(len(orgs), len(texts), len(years), len(occurences))\n",
    "\n",
    "# print(occurences[0])\n",
    "# print(years[0][:, 0])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "257 257 257 257\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "source": [
    "# Total linear regression\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "total_years = {}\n",
    "\n",
    "for year in years:\n",
    "    # print(year)\n",
    "    for k,v in year.items():\n",
    "        # print(k, v)\n",
    "        if k in total_years:\n",
    "            total_years[k] += v\n",
    "        else:\n",
    "            total_years[k] = v\n",
    "\n",
    "y = list(year.values())\n",
    "x = list(year.keys())\n",
    "x = np.array(x).reshape((-1, 1))\n",
    "\n",
    "model = LinearRegression().fit(x, y)\n",
    "slope = model.coef_\n",
    "total_slope = slope[0]\n",
    "# score = model.score(x, y)\n",
    "\n",
    "total_years, total_slope\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "({2011: 1197,\n",
       "  2012: 1135,\n",
       "  2013: 1945,\n",
       "  2014: 2613,\n",
       "  2015: 3265,\n",
       "  2016: 4031,\n",
       "  2017: 2663,\n",
       "  2018: 5059,\n",
       "  2019: 6712,\n",
       "  2020: 7735},\n",
       " -0.024242424242424242)"
      ]
     },
     "metadata": {},
     "execution_count": 100
    }
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "source": [
    "# Linear regression\n",
    "\n",
    "import matplotlib.colors\n",
    "\n",
    "slopes = []\n",
    "colors = []\n",
    "\n",
    "_min = 0\n",
    "_max = 0\n",
    "\n",
    "\n",
    "# Slope\n",
    "\n",
    "for year in years:\n",
    "\n",
    "    y = list(year.values())\n",
    "    x = list(year.keys())\n",
    "    x = np.array(x).reshape((-1, 1))\n",
    "    \n",
    "    model = LinearRegression().fit(x, y)\n",
    "    slope = model.coef_\n",
    "    slope = slope[0] - total_slope\n",
    "    # slope = slope[0]\n",
    "    score = model.score(x, y)\n",
    "    slopes.append(slope)\n",
    "\n",
    "    if slope > _max: _max = slope\n",
    "    if slope < _min: _min = slope\n",
    "\n",
    "    # print()\n",
    "    # print(list(year.keys()), y)\n",
    "    # print('slope', slope, 'score', score)\n",
    "\n",
    "print('min', _min, 'max', _max)\n",
    "\n",
    "# Colors\n",
    "\n",
    "cmap = plt.cm.RdYlBu_r\n",
    "cmap = plt.cm.coolwarm\n",
    "# norm = matplotlib.colors.Normalize(vmin=_min, vmax=_max)\n",
    "norm = matplotlib.colors.DivergingNorm(vmin=_min, vcenter=0, vmax=_max)\n",
    "# norm = matplotlib.colors.DivergingNorm(vmin=-10, vcenter=0, vmax=10)\n",
    "\n",
    "for slope in slopes:\n",
    "    color = cmap(norm(slope))\n",
    "    colors.append(color)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "min -1.739393939393939 max 26.933333333333323\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-101-50bf3f7e9c14>:41: MatplotlibDeprecationWarning: \n",
      "The DivergingNorm class was deprecated in Matplotlib 3.2 and will be removed two minor releases later. Use TwoSlopeNorm instead.\n",
      "  norm = matplotlib.colors.DivergingNorm(vmin=_min, vcenter=0, vmax=_max)\n"
     ]
    }
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "source": [
    "# Term Frequency Matrix\n",
    "\n",
    "import textacy\n",
    "\n",
    "doc_term_matrix, dictionary = textacy.representations.build_doc_term_matrix(texts, tf_type=\"linear\", idf_type=\"smooth\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "source": [
    "# UMAP\n",
    "\n",
    "import umap\n",
    "from pointgrid import align_points_to_grid\n",
    "\n",
    "reducer = umap.UMAP(n_components=2, n_neighbors=3, min_dist=0.001, metric='cosine')\n",
    "# reducer = umap.UMAP(random_state=2, n_components=2, n_neighbors=2, min_dist=0.01, metric='hellinger')\n",
    "\n",
    "embedding = reducer.fit_transform(doc_term_matrix)\n",
    "embedding = align_points_to_grid(embedding)\n",
    "x = embedding[:, 0]; y = embedding[:, 1]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " * creating mesh with size 51 51\n",
      " * filling mesh\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "source": [
    "# Clustering on embedding\n",
    "\n",
    "import hdbscan\n",
    "\n",
    "# clusterer = hdbscan.HDBSCAN(min_cluster_size=4, min_samples=3, cluster_selection_epsilon=.5)\n",
    "clusterer = hdbscan.HDBSCAN(min_cluster_size=3, min_samples=2)\n",
    "# clusterer = hdbscan.HDBSCAN(cluster_selection_epsilon=0.3, cluster_selection_method='leaf')\n",
    "# min_samples is to consier all the elements that owtherwide will be classified as noise\n",
    "# cluster_selection_epsilon extends clusters\n",
    "clusterer.fit(embedding)\n",
    "clusters = clusterer.labels_\n",
    "\n",
    "# Grouping by cluster\n",
    "\n",
    "values = set(clusters)\n",
    "if -1 in values: values.remove(-1)\n",
    "\n",
    "clusters = [[index for index, cluster in enumerate(clusters) if cluster==value] for value in values]\n",
    "\n",
    "len(clusters)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "metadata": {},
     "execution_count": 113
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "source": [
    "# Plot\n",
    "\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import ConvexHull\n",
    "from scipy import interpolate\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Frame\n",
    "\n",
    "plt.figure(figsize=(20,20), dpi=300)\n",
    "plt.axis('off')\n",
    "\n",
    "\n",
    "# Hulls\n",
    "\n",
    "for cluster in clusters:\n",
    "\n",
    "    # Average color\n",
    "    \n",
    "    background_color = []\n",
    "    \n",
    "    for i, index in enumerate(cluster):\n",
    "        for occurence in range(occurences[index]):\n",
    "            background_color.append([colors[index][0], colors[index][1], colors[index][2]])\n",
    "\n",
    "    r = [i[0] for i in background_color]; r = sum(r) / len(r)\n",
    "    g = [i[1] for i in background_color]; g = sum(g) / len(g)\n",
    "    b = [i[2] for i in background_color]; b = sum(b) / len(b)\n",
    "\n",
    "    background_color = (r, g, b, 1)\n",
    "\n",
    "    # Hull\n",
    "\n",
    "    points = []\n",
    "    for index in cluster:\n",
    "        points.append([embedding[index][0], embedding[index][1]])\n",
    "    points = np.array(points)\n",
    "\n",
    "    # print(points)\n",
    "\n",
    "    hull = ConvexHull(points)\n",
    "    \n",
    "    x_hull = np.append(points[hull.vertices,0], points[hull.vertices,0][0]) # Collect the xs + first x\n",
    "    y_hull = np.append(points[hull.vertices,1], points[hull.vertices,1][0])\n",
    "\n",
    "    # print(x_hull)\n",
    "\n",
    "    # break\n",
    "    \n",
    "    # interpolate\n",
    "    dist = np.sqrt((x_hull[:-1] - x_hull[1:])**2 + (y_hull[:-1] - y_hull[1:])**2)\n",
    "    dist_along = np.concatenate(([0], dist.cumsum()))\n",
    "    spline, u = interpolate.splprep([x_hull, y_hull], u=dist_along, s=0)\n",
    "    interp_d = np.linspace(dist_along[0], dist_along[-1], 50)\n",
    "    interp_x, interp_y = interpolate.splev(interp_d, spline)\n",
    "    \n",
    "    # plot shape\n",
    "    plt.fill(interp_x, interp_y, '--', c=background_color, alpha=.2)\n",
    "\n",
    "\n",
    "# Scatterplot\n",
    "\n",
    "# plt.scatter(x, y, s=occurences, c=colors)\n",
    "plt.scatter(x, y, s=40, c=colors)\n",
    "\n",
    "\n",
    "# Labels\n",
    "\n",
    "for i, txt in enumerate(orgs):\n",
    "    # text = plt.annotate(orgs[i], xy=(x[i], y[i] - math.sqrt(occurences[i]/math.pi)/40), ha='center', va='bottom')\n",
    "    text = plt.annotate(orgs[i], xy=(x[i], y[i]), ha='center', va='bottom')\n",
    "    text.set_fontsize(2)\n",
    "\n",
    "plt.savefig('/Users/dario/Desktop/download.png')\n",
    "plt.savefig('download.png')\n",
    "\n",
    "    \n",
    "\n"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "source": [
    "# Contours\n",
    "\n",
    "from random import random\n",
    "\n",
    "\n",
    "def f(x, y):\n",
    "    return np.sin(x) ** 10 + np.cos(10 + y * x) * np.cos(x)\n",
    "\n",
    "X, Y = np.meshgrid(x, y)\n",
    "\n",
    "Z = np.zeros((len(X),len(Y)))\n",
    "\n",
    "\n",
    "for indexX, elX in enumerate(X):\n",
    "    for indexY, elY in enumerate(Y):\n",
    "        # continue\n",
    "        # print(random() * 1000)\n",
    "        Z[indexX][indexY] = random() * 100\n",
    "Z\n",
    "\n",
    "# The proble is that I want to use \"slopes\" values which are monodimensional and not bidimensional\n",
    "\n",
    "plt.contour(X, Y, Z, colors='black', linewidths=.1)\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.contour.QuadContourSet at 0x7f80746be2e0>"
      ]
     },
     "metadata": {},
     "execution_count": 107
    }
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "iris = sns.load_dataset(\"iris\")\n",
    "\n",
    "# Set up the figure\n",
    "f, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.set_aspect(\"equal\")\n",
    "\n",
    "# Draw a contour plot to represent each bivariate density\n",
    "sns.kdeplot(\n",
    "    # data=iris.query(\"species != 'versicolor'\"),\n",
    "    x=x,\n",
    "    y=y,\n",
    "    # hue=\"species\",\n",
    "    thresh=.1,\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "metadata": {},
     "execution_count": 108
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ]
}