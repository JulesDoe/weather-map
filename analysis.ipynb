{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing the Whole Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 26450\n",
      "0  |  1000  |  2000  |  3000  |  4000  |  5000  |  6000  |  7000  |  8000  |  9000  |  10000  |  11000  |  12000  |  13000  |  14000  |  15000  |  16000  |  17000  |  18000  |  19000  |  20000  |  21000  |  22000  |  23000  |  24000  |  25000  |  26000  |  "
     ]
    }
   ],
   "source": [
    "# Reading the whole folder\n",
    "\n",
    "entities = []\n",
    "\n",
    "\n",
    "# The index of these four arrays corresponds to one organization\n",
    "\n",
    "orgs = []\n",
    "texts = []\n",
    "years = []\n",
    "occurences = []\n",
    "\n",
    "\n",
    "# The template counts the occurencies for each organization\n",
    "\n",
    "years_template = { 2011: 0, 2012: 0, 2013: 0, 2014: 0, 2015: 0, 2016: 0, 2017: 0, 2018: 0, 2019: 0, 2020: 0 }\n",
    "\n",
    "\n",
    "# Folder\n",
    "\n",
    "dir = 'data/biomass/'\n",
    "files = os.listdir(dir)\n",
    "print('Total', len(files))\n",
    "\n",
    "for index, filename in enumerate(files):\n",
    "\n",
    "    # Read file\n",
    "    \n",
    "    f = open(dir + filename)\n",
    "    r = f.read()\n",
    "    data = json.loads(r)\n",
    "    \n",
    "    \n",
    "    # Set basic metadata\n",
    "\n",
    "    try:\n",
    "        year = int(data[0]['publish_date'].split(' ')[0].split('-')[0]) # Set year\n",
    "        records = data[0]['story_tags'] # Set tags\n",
    "        if len(records) > 200: continue # Limit the maxiumum number of records\n",
    "        \n",
    "        if not index % 1000:\n",
    "            print(index, ' | ', end=' ')\n",
    "    \n",
    "    except:\n",
    "        continue\n",
    "\n",
    "\n",
    "    # Collect entities\n",
    "    \n",
    "    tags = []\n",
    "\n",
    "    for record in records:\n",
    "        # If the record is an organization\n",
    "        if (record['tag_set'] == 'cliff_organizations'):\n",
    "            \n",
    "            tag = record['tag']\n",
    "\n",
    "            if len(tag[0]) > 50:\n",
    "                continue\n",
    "\n",
    "            if tag[0].islower():\n",
    "                continue # If the tag starts with lowercase\n",
    "            \n",
    "            tag = tag.replace('.', '')\n",
    "            tag = tag.replace(',', '')\n",
    "            tag = tag.replace(', Inc', '')\n",
    "            tag = tag.replace(' Co', '')\n",
    "            tag = tag.replace('US ', '')\n",
    "            tag = tag.replace('mmission', ' Commission')\n",
    "            tag = tag.replace('llege', ' College')\n",
    "            tag = tag.replace('mmerce', ' Commerce')\n",
    "            tag = tag.replace('lumbia', ' Columbia')\n",
    "\n",
    "            if tag == 'ExxonMobil': tag = 'Exxon'\n",
    "            if tag == 'Exxon Mobil': tag = 'Exxon'\n",
    "            if tag == 'Interior': tag = 'Interior Department'\n",
    "            if tag == 'Reuters': tag = 'Thomson Reuters'\n",
    "            if tag == 'Royal Dutch Shell': tag = 'Shell'\n",
    "            if tag == 'World Health Organisation': tag = 'World Health Organization'\n",
    "\n",
    "            if tag == 'IMF': tag = 'International Monetary Fund'\n",
    "            if tag == 'International Monetary Found': tag = 'International Monetary Fund'\n",
    "            \n",
    "            if tag == 'European commission': tag = 'European Commission'\n",
    "\n",
    "            if tag == 'EU': tag = 'European Union'\n",
    "            if tag == 'UN': tag = 'United Nations'\n",
    "            if tag == 'NYSE': tag = 'New York Stock Exchange'\n",
    "            if tag == 'NRDC': tag = 'Natural Resources Defense Council'\n",
    "            if tag == 'GE': tag = 'General Electric'\n",
    "            if tag == 'EDF': tag = 'Environmental Defense Fund'\n",
    "            if tag == 'EPA': tag = 'Environmental Protection Agency'\n",
    "            if tag == 'FDA': tag = 'Food and Drug Administration'\n",
    "            if tag == 'GOP': tag = 'Republican Party'\n",
    "            if tag == 'PG&E': tag = 'Pacific Gas & Electric'\n",
    "            if tag == 'Xcel': tag = 'Xcel Energy'\n",
    "            if tag == 'EIA': tag = 'Energy Information Administration'\n",
    "            if tag == 'AP': tag = 'Associated Press'\n",
    "            if tag == 'NOAA': tag = 'National Oceanic and Atmospheric Administration'\n",
    "            if tag == 'PUC': tag = 'Public Utilities Commission'\n",
    "            if tag == 'IFC': tag = 'International Finance Corporation'\n",
    "            if tag == 'SEC': tag = 'Securities and Exchange Commission'\n",
    "            if tag == 'IFC': tag = 'Internarnational Finance Corporation'\n",
    "            if tag == 'NREL': tag = 'National Renewable Energy Laboratory'\n",
    "            if tag == 'UNDP': tag = 'United Nations Development Programme'\n",
    "            if tag == 'S&P': tag = 'S&P Global Ratings'\n",
    "            if tag == 'IEA': tag = 'International Energy Agency'\n",
    "            if tag == 'FPL': tag = 'Florida Power & Light'\n",
    "            \n",
    "            if tag == 'USDA': tag = 'Agriculture Department'\n",
    "            if tag == 'Agriculture': tag = 'Agriculture Department'\n",
    "            if tag == 'Department of Agriculture': tag = 'Agriculture Department'\n",
    "\n",
    "            if tag == 'DOE': tag = 'Energy Department'\n",
    "            if tag == 'Energy': tag = 'Energy Department'\n",
    "            if tag == 'Department of Energy': tag = 'Energy Department'\n",
    "            if tag == 'State': tag = 'State Department'\n",
    "\n",
    "            if tag == 'House': tag = 'White House'\n",
    "            \n",
    "            if tag == 'Yale': tag = 'Yale University'\n",
    "            if tag == 'Penn State': tag = 'Pennsylvania State University'\n",
    "            if tag == 'Oxford of University': tag = 'University Oxford'\n",
    "            if tag == 'Oxford': tag = 'Oxford University'\n",
    "            if tag == 'Stanford': tag = 'Stanford University'\n",
    "            if tag == 'Massachusetts Institute of Technology': tag = 'MIT'\n",
    "            if tag == 'Harvard': tag = 'Harvard University'\n",
    "            if tag == 'University of California, Berkeley': tag = 'University of California'\n",
    "\n",
    "            if tag.startswith('Valens'): tag = 'Valens'\n",
    "            if tag.startswith('Siemens'): tag = 'Siemens'\n",
    "            if tag.startswith('Bloomberg'): tag = 'Bloomberg'\n",
    "            if tag.startswith('BBC'): tag = 'BBC'\n",
    "            if tag.startswith('United Nations'): tag = 'United Nations'\n",
    "\n",
    "            if '   ' in tag:\n",
    "                split = tag.split('   ')\n",
    "                tag = split[0]\n",
    "            \n",
    "            # if tag.startswith('Magazine   '):\n",
    "            #     continue\n",
    "            # if tag.startswith('Somerset  '):\n",
    "            #     continue\n",
    "            \n",
    "            stoplist = {'Inc', 'NCR', 'U', 'EVs'}\n",
    "            \n",
    "            if tag not in stoplist:\n",
    "                tags.append(tag)\n",
    "    \n",
    "    \n",
    "    # Create data structure\n",
    "\n",
    "    for t in tags:\n",
    "\n",
    "        related = tags.copy()\n",
    "        related.remove(t)    \n",
    "    \n",
    "        if t not in orgs:\n",
    "            orgs.append(t)\n",
    "            i = orgs.index(t)\n",
    "            texts.append(related)\n",
    "            occurences.append(1)\n",
    "            years.append(years_template.copy())\n",
    "            years[i][year] += 1\n",
    "                \n",
    "        else:\n",
    "            i = orgs.index(t)\n",
    "            texts[i] += related\n",
    "            occurences[i] += 1\n",
    "            years[i][year] += 1\n",
    "\n",
    "    # if index > 10:\n",
    "    #     raise SystemExit(\"Stop right there!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_orgs = orgs.copy()\n",
    "copy_texts = texts.copy()\n",
    "copy_years = years.copy()\n",
    "copy_occurences = occurences.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CVS Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "pairs = []\n",
    "with open('orgs.csv', 'w', encoding='UTF8') as f:\n",
    "    for n in orgs:\n",
    "        i = orgs.index(n)\n",
    "        f.write(n + \",\" + str(len(n)) + ',' + str(occurences[i]) + '\\n')\n",
    "        # pairs.append([n, occurences[i]])\n",
    "\n",
    "    # writer = csv.writer(f)\n",
    "    # writer.writerow(pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121 121 121 121\n"
     ]
    }
   ],
   "source": [
    "orgs = copy_orgs.copy()\n",
    "texts = copy_texts.copy()\n",
    "years = copy_years.copy()\n",
    "occurences = copy_occurences.copy()\n",
    "\n",
    "# Remove less citates organizations\n",
    "\n",
    "for index, occurrence in reversed(list(enumerate(occurences))):\n",
    "\n",
    "    min = 80\n",
    "\n",
    "    if occurrence < min:\n",
    "        orgs.pop(index)\n",
    "        texts.pop(index)\n",
    "        years.pop(index)\n",
    "        occurences.pop(index)\n",
    "    # else:\n",
    "        # print()\n",
    "        # print(index, occurrence, orgs[index])\n",
    "        # print()\n",
    "\n",
    "# order years by key in an array of tuples\n",
    "\n",
    "for index, y in enumerate(years):\n",
    "    sortedDict = dict( sorted(y.items(), key=lambda x: x[0]) )\n",
    "    _temp = {}\n",
    "    for k,v in sortedDict.items():\n",
    "        _temp[k] = v\n",
    "    years[index] = _temp\n",
    "\n",
    "print(len(orgs), len(texts), len(years), len(occurences))\n",
    "\n",
    "# print(occurences[0])\n",
    "# print(years[0][:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({2011: 1133,\n",
       "  2012: 1027,\n",
       "  2013: 1765,\n",
       "  2014: 2351,\n",
       "  2015: 2897,\n",
       "  2016: 3486,\n",
       "  2017: 2282,\n",
       "  2018: 4142,\n",
       "  2019: 5645,\n",
       "  2020: 6353},\n",
       " 4.7393939393939375)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total linear regression\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "total_years = {}\n",
    "\n",
    "for year in years:\n",
    "    # print(year)\n",
    "    for k,v in year.items():\n",
    "        # print(k, v)\n",
    "        if k in total_years:\n",
    "            total_years[k] += v\n",
    "        else:\n",
    "            total_years[k] = v\n",
    "\n",
    "y = list(year.values())\n",
    "x = list(year.keys())\n",
    "x = np.array(x).reshape((-1, 1))\n",
    "\n",
    "model = LinearRegression().fit(x, y)\n",
    "slope = model.coef_\n",
    "total_slope = slope[0]\n",
    "# score = model.score(x, y)\n",
    "\n",
    "total_years, total_slope\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min -6.5030303030303 max 52.52121212121211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-214-50bf3f7e9c14>:41: MatplotlibDeprecationWarning: \n",
      "The DivergingNorm class was deprecated in Matplotlib 3.2 and will be removed two minor releases later. Use TwoSlopeNorm instead.\n",
      "  norm = matplotlib.colors.DivergingNorm(vmin=_min, vcenter=0, vmax=_max)\n"
     ]
    }
   ],
   "source": [
    "# Linear regression\n",
    "\n",
    "import matplotlib.colors\n",
    "\n",
    "slopes = []\n",
    "colors = []\n",
    "\n",
    "_min = 0\n",
    "_max = 0\n",
    "\n",
    "\n",
    "# Slope\n",
    "\n",
    "for year in years:\n",
    "\n",
    "    y = list(year.values())\n",
    "    x = list(year.keys())\n",
    "    x = np.array(x).reshape((-1, 1))\n",
    "    \n",
    "    model = LinearRegression().fit(x, y)\n",
    "    slope = model.coef_\n",
    "    slope = slope[0] - total_slope\n",
    "    # slope = slope[0]\n",
    "    score = model.score(x, y)\n",
    "    slopes.append(slope)\n",
    "\n",
    "    if slope > _max: _max = slope\n",
    "    if slope < _min: _min = slope\n",
    "\n",
    "    # print()\n",
    "    # print(list(year.keys()), y)\n",
    "    # print('slope', slope, 'score', score)\n",
    "\n",
    "print('min', _min, 'max', _max)\n",
    "\n",
    "# Colors\n",
    "\n",
    "cmap = plt.cm.RdYlBu_r\n",
    "cmap = plt.cm.coolwarm\n",
    "# norm = matplotlib.colors.Normalize(vmin=_min, vmax=_max)\n",
    "norm = matplotlib.colors.DivergingNorm(vmin=_min, vcenter=0, vmax=_max)\n",
    "# norm = matplotlib.colors.DivergingNorm(vmin=-10, vcenter=0, vmax=10)\n",
    "\n",
    "for slope in slopes:\n",
    "    color = cmap(norm(slope))\n",
    "    colors.append(color)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Term Frequency Matrix\n",
    "\n",
    "import textacy\n",
    "\n",
    "doc_term_matrix, dictionary = textacy.representations.build_doc_term_matrix(texts, tf_type=\"linear\", idf_type=\"smooth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * creating mesh with size 35 35\n",
      " * filling mesh\n"
     ]
    }
   ],
   "source": [
    "# UMAP\n",
    "\n",
    "import umap\n",
    "from pointgrid import align_points_to_grid\n",
    "\n",
    "reducer = umap.UMAP(n_components=2, n_neighbors=2, min_dist=0.001, metric='cosine')\n",
    "# reducer = umap.UMAP(random_state=2, n_components=2, n_neighbors=2, min_dist=0.01, metric='hellinger')\n",
    "\n",
    "embedding = reducer.fit_transform(doc_term_matrix)\n",
    "embedding = align_points_to_grid(embedding)\n",
    "x = embedding[:, 0]; y = embedding[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clustering on embedding\n",
    "\n",
    "import hdbscan\n",
    "\n",
    "# clusterer = hdbscan.HDBSCAN(min_cluster_size=4, min_samples=3, cluster_selection_epsilon=.5)\n",
    "clusterer = hdbscan.HDBSCAN(min_cluster_size=3, min_samples=2)\n",
    "# clusterer = hdbscan.HDBSCAN(cluster_selection_epsilon=0.3, cluster_selection_method='leaf')\n",
    "# min_samples is to consier all the elements that owtherwide will be classified as noise\n",
    "# cluster_selection_epsilon extends clusters\n",
    "clusterer.fit(embedding)\n",
    "clusters = clusterer.labels_\n",
    "\n",
    "# Grouping by cluster\n",
    "\n",
    "values = set(clusters)\n",
    "if -1 in values: values.remove(-1)\n",
    "\n",
    "clusters = [[index for index, cluster in enumerate(clusters) if cluster==value] for value in values]\n",
    "\n",
    "len(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot\n",
    "\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import ConvexHull\n",
    "from scipy import interpolate\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Frame\n",
    "\n",
    "plt.figure(figsize=(20,20), dpi=300)\n",
    "plt.axis('off')\n",
    "\n",
    "\n",
    "# Hulls\n",
    "\n",
    "for cluster in clusters:\n",
    "\n",
    "    # Average color\n",
    "    \n",
    "    background_color = []\n",
    "    \n",
    "    for i, index in enumerate(cluster):\n",
    "        for occurence in range(occurences[index]):\n",
    "            background_color.append([colors[index][0], colors[index][1], colors[index][2]])\n",
    "\n",
    "    r = [i[0] for i in background_color]; r = sum(r) / len(r)\n",
    "    g = [i[1] for i in background_color]; g = sum(g) / len(g)\n",
    "    b = [i[2] for i in background_color]; b = sum(b) / len(b)\n",
    "\n",
    "    background_color = (r, g, b, 1)\n",
    "\n",
    "    # Hull\n",
    "\n",
    "    points = []\n",
    "    for index in cluster:\n",
    "        points.append([embedding[index][0], embedding[index][1]])\n",
    "    points = np.array(points)\n",
    "\n",
    "    # print(points)\n",
    "\n",
    "    hull = ConvexHull(points)\n",
    "    \n",
    "    x_hull = np.append(points[hull.vertices,0], points[hull.vertices,0][0]) # Collect the xs + first x\n",
    "    y_hull = np.append(points[hull.vertices,1], points[hull.vertices,1][0])\n",
    "\n",
    "    # print(x_hull)\n",
    "\n",
    "    # break\n",
    "    \n",
    "    # interpolate\n",
    "    dist = np.sqrt((x_hull[:-1] - x_hull[1:])**2 + (y_hull[:-1] - y_hull[1:])**2)\n",
    "    dist_along = np.concatenate(([0], dist.cumsum()))\n",
    "    spline, u = interpolate.splprep([x_hull, y_hull], u=dist_along, s=0)\n",
    "    interp_d = np.linspace(dist_along[0], dist_along[-1], 50)\n",
    "    interp_x, interp_y = interpolate.splev(interp_d, spline)\n",
    "    \n",
    "    # plot shape\n",
    "    plt.fill(interp_x, interp_y, '--', c=background_color, alpha=.2)\n",
    "\n",
    "\n",
    "# Scatterplot\n",
    "\n",
    "# plt.scatter(x, y, s=occurences, c=colors)\n",
    "plt.scatter(x, y, s=40, c=colors)\n",
    "\n",
    "\n",
    "# Labels\n",
    "\n",
    "for i, txt in enumerate(orgs):\n",
    "    # text = plt.annotate(orgs[i], xy=(x[i], y[i] - math.sqrt(occurences[i]/math.pi)/40), ha='center', va='bottom')\n",
    "    text = plt.annotate(orgs[i], xy=(x[i], y[i]), ha='center', va='bottom')\n",
    "    text.set_fontsize(3)\n",
    "\n",
    "plt.savefig('/Users/dario/Desktop/download.png')\n",
    "plt.savefig('download.png')\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.contour.QuadContourSet at 0x7fac8d8c1d30>"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Contours\n",
    "\n",
    "from random import random\n",
    "\n",
    "\n",
    "def f(x, y):\n",
    "    return np.sin(x) ** 10 + np.cos(10 + y * x) * np.cos(x)\n",
    "\n",
    "X, Y = np.meshgrid(x, y)\n",
    "\n",
    "Z = np.zeros((len(X),len(Y)))\n",
    "\n",
    "\n",
    "for indexX, elX in enumerate(X):\n",
    "    for indexY, elY in enumerate(Y):\n",
    "        # continue\n",
    "        # print(random() * 1000)\n",
    "        Z[indexX][indexY] = random() * 100\n",
    "Z\n",
    "\n",
    "# The proble is that I want to use \"slopes\" values which are monodimensional and not bidimensional\n",
    "\n",
    "plt.contour(X, Y, Z, colors='black', linewidths=.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "iris = sns.load_dataset(\"iris\")\n",
    "\n",
    "# Set up the figure\n",
    "f, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.set_aspect(\"equal\")\n",
    "\n",
    "# Draw a contour plot to represent each bivariate density\n",
    "sns.kdeplot(\n",
    "    # data=iris.query(\"species != 'versicolor'\"),\n",
    "    x=x,\n",
    "    y=y,\n",
    "    # hue=\"species\",\n",
    "    thresh=.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f85c0ae1067a86ad6a96b144378883e79fd1516474b579ba33ee3a7084540002"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
